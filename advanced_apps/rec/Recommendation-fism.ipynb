{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setting\n",
    "\n",
    "In this tutorial, we demonstrate how graph neural networks can be used for recommendation. Here we focus on item-based recommendation model. This method in this tutorial recommends items that are similar to the ones purchased by the user. We demonstrate the recommendation model on the MovieLens dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started\n",
    "\n",
    "DGL can be used with different deep learning frameworks. Currently, DGL can be used with Pytorch and MXNet. Here, we show how DGL works with Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we load DGL, we need to set the DGL backend for one of the deep learning frameworks. Because this tutorial develops models in Pytorch, we have to set the DGL backend to Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "\n",
    "# Load Pytorch as backend\n",
    "dgl.load_backend('pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the rest of necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import sparse as spsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We use the MoiveLens dataset for demonstration because it is commonly used for recommendation models. In this dataset, there are two types of nodes: users and movies. The movie nodes have three attributes: year, title and genre. There are ratings between user nodes and movie nodes. Each rating has a timestamp. In our recommendation model, we don't consider ratings and timestamps.\n",
    "\n",
    "**Note**: It is not necessarily the best dataset to demonstrate the power of GNN for recommendation. We have prepared the dataset to simplify the demonstration.\n",
    "\n",
    "To run the data preprocessing script, a user needs to download the English dictionary of the stanfordnlp package first. However, the following command only needs to run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment the two commands when the tutorial is run for the first time.\n",
    "#import stanfordnlp\n",
    "#stanfordnlp.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from movielens import MovieLens\n",
    "data = MovieLens('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate some statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = data.ratings\n",
    "user_id = np.array(ratings['user_idx'])\n",
    "movie_id = np.array(ratings['movie_idx'])\n",
    "user_movie_spm = spsp.coo_matrix((np.ones((len(user_id),)), (user_id, movie_id)))\n",
    "num_users, num_movies = user_movie_spm.shape\n",
    "print('#user-movie iterations:', len(movie_id))\n",
    "print('#users:', num_users)\n",
    "print('#movies:', num_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation and testing sets. In the validation and testing dataset, each user has an item to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_test(user_movie_spm):\n",
    "    users = user_movie_spm.row\n",
    "    movies = user_movie_spm.col\n",
    "    picks = np.zeros(shape=(len(users)))\n",
    "    user_movie_spm = user_movie_spm.tocsr()\n",
    "    indptr = user_movie_spm.indptr\n",
    "    valid_set = np.zeros(shape=(num_users))\n",
    "    test_set = np.zeros(shape=(num_users))\n",
    "    for i in range(user_movie_spm.shape[0]):\n",
    "        start_idx = indptr[i]\n",
    "        end_idx = indptr[i+1]\n",
    "        idx = np.random.choice(np.arange(start_idx, end_idx), 2, replace=False)\n",
    "        valid_set[i] = movies[idx[0]]\n",
    "        picks[idx[0]] = 1\n",
    "        test_set[i] = movies[idx[1]]\n",
    "        picks[idx[1]] = 1\n",
    "    users = users[picks == 0]\n",
    "    movies = movies[picks == 0]\n",
    "    return spsp.coo_matrix((np.ones((len(users),)), (users, movies))), valid_set, test_set\n",
    "\n",
    "orig_user_movie_spm = user_movie_spm.tocsr()\n",
    "user_movie_spm, valid_set, test_set = pick_test(user_movie_spm)\n",
    "print('#training size:', user_movie_spm.nnz)\n",
    "users_valid = np.arange(num_users)\n",
    "movies_valid = valid_set\n",
    "users_test = np.arange(num_users)\n",
    "movies_test = test_set\n",
    "valid_size = len(users_valid)\n",
    "test_size = len(users_test)\n",
    "print('valid set:', valid_size)\n",
    "print('test set:', test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data split in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo = user_movie_spm.tocoo()\n",
    "train_map = {}\n",
    "valid_map = {}\n",
    "test_map = {}\n",
    "#print the training set.\n",
    "with open(\"train.txt\",\"w\") as file:\n",
    "    for row, col in zip(coo.row, coo.col):\n",
    "        train_map[(row, col)] = 1\n",
    "        file.write(str(row) + ', ' + str(col) + '\\n')\n",
    "    file.close()\n",
    "with open('valid.txt', 'w') as file:\n",
    "    for row, col in enumerate(valid_set):\n",
    "        valid_map[(row, col)] = 1\n",
    "        file.write(str(row) + ', ' + str(int(col)) + '\\n')\n",
    "    file.close()\n",
    "with open('test.txt', 'w') as file:\n",
    "    for row, col in enumerate(test_set):\n",
    "        test_map[(row, col)] = 1\n",
    "        file.write(str(row) + ', ' + str(int(col)) + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the negative samples are actually positive. Here we try to remove all of the postive ones from the negative set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_neg_set(user_movie_spm, neg_sample_size):\n",
    "    num_users = user_movie_spm.shape[0]\n",
    "    num_movies = user_movie_spm.shape[1]\n",
    "    neg_mat = np.zeros(shape=(num_users, neg_sample_size))\n",
    "    for user in range(num_users):\n",
    "        movie_set = set()\n",
    "        while len(movie_set) < neg_sample_size:\n",
    "            movies = np.random.choice(num_movies, neg_sample_size, replace=False)\n",
    "            for movie in movies:\n",
    "                if user_movie_spm[user, movie] == 0:\n",
    "                    movie_set.add(movie)\n",
    "                if len(movie_set) == neg_sample_size:\n",
    "                    break\n",
    "        neg_mat[user] = np.array(list(movie_set))\n",
    "\n",
    "    for user, movies in enumerate(neg_mat):\n",
    "        for idx, movie in enumerate(movies):\n",
    "            assert user_movie_spm[user, movie] == 0\n",
    "                \n",
    "    return neg_mat\n",
    "\n",
    "neg_valid = gen_neg_set(orig_user_movie_spm.tocsr(), 99)\n",
    "neg_test = gen_neg_set(orig_user_movie_spm.tocsr(), 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the negative sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neg_valid.txt', 'w') as file:\n",
    "    for row, cols in enumerate(neg_valid):\n",
    "        for col in cols:\n",
    "            assert (row, col) not in train_map\n",
    "            assert (row, col) not in valid_map\n",
    "            assert (row, col) not in test_map\n",
    "            file.write(str(row) + ', ' + str(int(col)) + '\\n')\n",
    "    file.close()\n",
    "\n",
    "with open('neg_test.txt', 'w') as file:\n",
    "    for row, cols in enumerate(neg_test):\n",
    "        for col in cols:\n",
    "            assert (row, col) not in train_map\n",
    "            assert (row, col) not in valid_map\n",
    "            assert (row, col) not in test_map\n",
    "            file.write(str(row) + ', ' + str(int(col)) + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data split is based on timestamp. Let's not use it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# The training dataset\n",
    "user_id = np.array(ratings_train['user_idx'])\n",
    "movie_id = np.array(ratings_train['movie_idx'])\n",
    "user_movie_spm = spsp.coo_matrix((np.ones((len(user_id),)), (user_id, movie_id)))\n",
    "assert num_users == user_movie_spm.shape[0]\n",
    "assert num_movies == user_movie_spm.shape[1]\n",
    "train_size = len(user_id)\n",
    "print('#training size:', train_size)\n",
    "\n",
    "# The validation and testing dataset\n",
    "users_valid = ratings[ratings['valid_mask']]['user_idx'].values\n",
    "movies_valid = ratings[ratings['valid_mask']]['movie_idx'].values\n",
    "users_test = ratings[ratings['test_mask']]['user_idx'].values\n",
    "movies_test = ratings[ratings['test_mask']]['movie_idx'].values\n",
    "valid_size = len(users_valid)\n",
    "test_size = len(users_test)\n",
    "print('valid set:', valid_size)\n",
    "print('test set:', test_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the item features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.expand_dims(data.movie_data['year'], axis=1)\n",
    "genre = data.movie_data['genre']\n",
    "title = data.movie_data['title']\n",
    "features = torch.tensor(np.concatenate((genre, title), axis=1), dtype=torch.float32)\n",
    "print('#features:', features.shape[1])\n",
    "in_feats = features.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save everything in pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(user_movie_spm, open('movielens_orig_train.pkl', 'wb'))\n",
    "pickle.dump(g, open('movielens_graph.pkl', 'wb'))\n",
    "pickle.dump(features, open('movielens_features.pkl', 'wb'))\n",
    "pickle.dump((valid_set, test_set), open('movielens_eval.pkl', 'wb'))\n",
    "pickle.dump((neg_valid, neg_test), open('movielens_neg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MovieLens from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "user_movie_spm = pickle.load(open('movielens/movielens_orig_train.pkl', 'rb'))\n",
    "features = pickle.load(open('movielens/movielens_features.pkl', 'rb'))\n",
    "valid_set, test_set = pickle.load(open('movielens/movielens_eval.pkl', 'rb'))\n",
    "neg_valid, neg_test = pickle.load(open('movielens/movielens_neg.pkl', 'rb'))\n",
    "\n",
    "num_users = user_movie_spm.shape[0]\n",
    "num_movies = user_movie_spm.shape[1]\n",
    "\n",
    "users_valid = np.arange(num_users)\n",
    "movies_valid = valid_set\n",
    "users_test = np.arange(num_users)\n",
    "movies_test = test_set\n",
    "\n",
    "movie_popularity = user_movie_spm.transpose().dot(np.ones(shape=(num_users)))\n",
    "# We need to rescale the values\n",
    "movie_popularity = torch.tensor(movie_popularity / np.max(movie_popularity), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "u, s, vt = spsp.linalg.svds(user_movie_spm)\n",
    "v = torch.tensor(vt.transpose(), dtype=torch.float32)\n",
    "v = v * torch.tensor(np.sqrt(s).transpose(), dtype=torch.float32)\n",
    "\n",
    "#features = torch.cat([features, movie_popularity, v], 1)\n",
    "one_hot = torch.tensor(np.diag(np.ones(shape=(num_movies))), dtype=torch.float32)\n",
    "features = torch.cat([features, one_hot], 1)\n",
    "in_feats = features.shape[1]\n",
    "print('#feats:', in_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BookCrossing from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "user_movie_spm = pickle.load(open('bx/bx_train.pkl', 'rb'))\n",
    "abstracts = pickle.load(open('bx/bx_book_abstract.pkl', 'rb'))\n",
    "titles = pickle.load(open('bx/bx_book_title.pkl', 'rb'))\n",
    "features = torch.tensor(np.concatenate((titles, abstracts), 1), dtype=torch.float32)\n",
    "valid_set, test_set = pickle.load(open('bx/bx_eval.pkl', 'rb'))\n",
    "neg_valid, neg_test = pickle.load(open('bx/bx_neg.pkl', 'rb'))\n",
    "\n",
    "num_users = user_movie_spm.shape[0]\n",
    "num_movies = user_movie_spm.shape[1]\n",
    "\n",
    "users_valid = np.arange(num_users, dtype=np.int64)\n",
    "movies_valid = valid_set\n",
    "users_test = np.arange(num_users, dtype=np.int64)\n",
    "movies_test = test_set\n",
    "\n",
    "#features = torch.cat([features, movie_popularity, v], 1)\n",
    "#one_hot = torch.tensor(np.diag(np.ones(shape=(num_movies))), dtype=torch.float32)\n",
    "#features = torch.cat([features, one_hot], 1)\n",
    "in_feats = features.shape[1]\n",
    "print('#feats:', in_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_deg = user_movie_spm.dot(np.ones((num_movies)))\n",
    "print(len(user_deg))\n",
    "user_deg1 = np.nonzero(user_deg == 1)[0]\n",
    "user_deg2 = np.nonzero(user_deg == 2)[0]\n",
    "user_deg3 = np.nonzero(user_deg == 3)[0]\n",
    "user_deg4 = np.nonzero(user_deg == 4)[0]\n",
    "user_deg5 = np.nonzero(user_deg == 5)[0]\n",
    "user_deg6 = np.nonzero(user_deg == 6)[0]\n",
    "user_deg7 = np.nonzero(user_deg == 7)[0]\n",
    "user_deg8 = np.nonzero(user_deg == 8)[0]\n",
    "user_deg9 = np.nonzero(user_deg == 9)[0]\n",
    "user_deg10 = np.nonzero(np.logical_and(10 <= user_deg, user_deg < 20))[0]\n",
    "user_deg20 = np.nonzero(np.logical_and(20 <= user_deg, user_deg < 30))[0]\n",
    "user_deg30 = np.nonzero(np.logical_and(30 <= user_deg, user_deg < 40))[0]\n",
    "user_deg40 = np.nonzero(np.logical_and(40 <= user_deg, user_deg < 50))[0]\n",
    "user_deg50 = np.nonzero(np.logical_and(50 <= user_deg, user_deg < 60))[0]\n",
    "user_deg60 = np.nonzero(np.logical_and(60 <= user_deg, user_deg < 70))[0]\n",
    "user_deg70 = np.nonzero(np.logical_and(70 <= user_deg, user_deg < 80))[0]\n",
    "user_deg80 = np.nonzero(np.logical_and(80 <= user_deg, user_deg < 90))[0]\n",
    "user_deg90 = np.nonzero(np.logical_and(90 <= user_deg, user_deg < 100))[0]\n",
    "user_deg100 = np.nonzero(user_deg >= 100)[0]\n",
    "print(len(user_deg1))\n",
    "print(len(user_deg2))\n",
    "print(len(user_deg3))\n",
    "print(len(user_deg4))\n",
    "print(len(user_deg5))\n",
    "print(len(user_deg6))\n",
    "print(len(user_deg7))\n",
    "print(len(user_deg8))\n",
    "print(len(user_deg9))\n",
    "print(len(user_deg10))\n",
    "print(len(user_deg20))\n",
    "print(len(user_deg30))\n",
    "print(len(user_deg40))\n",
    "print(len(user_deg50))\n",
    "print(len(user_deg60))\n",
    "print(len(user_deg70))\n",
    "print(len(user_deg80))\n",
    "print(len(user_deg90))\n",
    "print(len(user_deg100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the items watched/read/used by users in the testing set and their popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_deg = user_movie_spm.transpose().dot(np.ones((num_users)))\n",
    "test_deg = np.zeros((num_users))\n",
    "for i in range(num_users):\n",
    "    movie = int(movies_test[i])\n",
    "    test_deg[i] = movie_deg[movie]\n",
    "test_deg_dict = {}\n",
    "for i in range(1, 10):\n",
    "    test_deg_dict[i] = np.nonzero(test_deg == i)[0]\n",
    "for i in range(1, 10):\n",
    "    test_deg_dict[i*10] = np.nonzero(np.logical_and(i*10 <= test_deg, test_deg < (i+1)*10))[0]\n",
    "test_deg_dict[100] = np.nonzero(test_deg >= 100)[0]\n",
    "tmp = 0\n",
    "for key, deg in test_deg_dict.items():\n",
    "    print(key, len(deg))\n",
    "    tmp += len(deg)\n",
    "print(num_users, tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The recommendation model\n",
    "\n",
    "At large, the model first learns item embeddings from the user-item interaction dataset and use the item embeddings to recommend users similar items they have purchased. To learn item embeddings, we first need to construct an item similarity graph and train GNN on the item graph.\n",
    "\n",
    "There are many ways of constructing the item similarity graph. Here we use the [SLIM model](https://dl.acm.org/citation.cfm?id=2118303) to learn item similarity and use the learned result to construct the item graph. The resulting graph will have an edge between two items if they are similar and the edge has a weight that represents the similarity score.\n",
    "\n",
    "After the item similarity graph is constructed, we run a GNN model on it and use the vertex connectivity as the training signal to train the GNN model. The GNN training procedure is very similar to the link prediction task in [the previous section](https://github.com/zheng-da/DGL_devday_tutorial/blob/master/BasicTasks_pytorch.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the movie graph with SLIM\n",
    "SLIM is an item-based recommendation model. When training SLIM on a user-item dataset, it learns an item similarity graph. This similarity graph is the item graph we construct for the GNN model.\n",
    "\n",
    "Please follow the instruction on the [SLIM github repo](https://github.com/KarypisLab/SLIM) to install SLIM.\n",
    "\n",
    "The SLIM only needs to run once and can be saved on the disk for future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLIM import SLIM, SLIMatrix\n",
    "model = SLIM()\n",
    "params = {'algo': 'cd', 'nthreads': 32, 'l1r': 0.1, 'l2r': 2000}\n",
    "trainmat = SLIMatrix(user_movie_spm.tocsr())\n",
    "model.train(params, trainmat)\n",
    "#model.save_model(modelfname='slim_model.csr', mapfname='slim_map.csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the SLIM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {}\n",
    "neg_sample_size = neg_test.shape[1]\n",
    "for i, neg_items in enumerate(neg_test):\n",
    "    candidates[i] = np.zeros(shape=(neg_items.shape[0] + 1,), dtype=np.int64)\n",
    "    candidates[i][:neg_sample_size] = neg_items\n",
    "    candidates[i][-1] = int(movies_test[i])\n",
    "rcmd_list = model.predict(trainmat, nrcmds=10, negitems=candidates, nnegs=100)\n",
    "rcmd_mat = np.ones(shape=(num_users, len(rcmd_list[0])), dtype=np.int64)\n",
    "for i, rcmd in rcmd_list.items():\n",
    "    rcmd_mat[i] = rcmd\n",
    "\n",
    "def test(rcmd_mat, true_list):\n",
    "    hits = 0\n",
    "    true_list = np.expand_dims(true_list, 1)\n",
    "    hits = np.sum(rcmd_mat == true_list)\n",
    "    #for u, rlist in rcmd_list.items():\n",
    "    #    hits += true_list[u] in rlist\n",
    "    print(\"Number of test(valid) users: %d(%d), hits@%d: %.4f\" % \n",
    "          (len(true_list), len(rcmd_list), len(rcmd_list[0]), hits / len(rcmd_list)))\n",
    "    return hits / len(rcmd_list)\n",
    "test(rcmd_mat, movies_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SLIM similarity matrix into DGL. We store the vertex similarity as edge data on DGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slim_load import read_csr\n",
    "\n",
    "movie_spm = read_csr('slim_model.csr')\n",
    "print('#edges:', movie_spm.nnz)\n",
    "print('most similar:', np.max(movie_spm.data))\n",
    "print('most unsimilar:', np.min(movie_spm.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = movie_spm.dot(np.ones((num_movies)))\n",
    "print(np.sum(deg == 0))\n",
    "print(len(deg))\n",
    "print(movie_spm.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.DGLGraph(movie_spm, readonly=True)\n",
    "g.edata['similarity'] = torch.tensor(movie_spm.data, dtype=torch.float32)\n",
    "g.ndata['title'] = torch.tensor(titles, dtype=torch.float32)\n",
    "g.ndata['abstract'] = torch.tensor(abstracts, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the co-watch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = user_movie_spm.row\n",
    "movie_id = user_movie_spm.col\n",
    "movie_deg = user_movie_spm.transpose().dot(np.ones((num_users,)))\n",
    "movie_ratio = movie_deg / np.sum(movie_deg)\n",
    "# 1e-6 is a hyperparameter for this dataset.\n",
    "movie_sample_prob = 1 - np.maximum(1 - np.sqrt(1e-5 / movie_ratio), 0)\n",
    "sample_prob = movie_sample_prob[movie_id]\n",
    "sample = np.random.uniform(size=(len(movie_id),))\n",
    "user_id = user_id[sample_prob > sample]\n",
    "movie_id = movie_id[sample_prob > sample]\n",
    "print('#samples:', len(user_id))\n",
    "spm = spsp.coo_matrix((np.ones((len(user_id),)), (user_id, movie_id)))\n",
    "print(spm.shape)\n",
    "movie_deg = spm.transpose().dot(np.ones((num_users,)))\n",
    "print(np.sum(movie_deg == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top co-watched movie pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_spm = np.dot(spm.transpose(), spm)\n",
    "print(movie_spm.nnz)\n",
    "dense_movie = np.sort(movie_spm.todense())\n",
    "topk_movie = dense_movie[:,-50]\n",
    "topk_movie_spm = movie_spm > topk_movie\n",
    "topk_movie_spm = spsp.csr_matrix(topk_movie_spm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the movie pairs with top K similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "movie_spm = cosine_similarity(user_movie_spm.transpose(),dense_output=False)\n",
    "\n",
    "dense_movie = np.sort(movie_spm.todense())\n",
    "topk_movie = dense_movie[:,-30]\n",
    "topk_movie_spm = movie_spm > topk_movie\n",
    "topk_movie_spm = spsp.csr_matrix(topk_movie_spm)\n",
    "topk_movie_spm = movie_spm.multiply(topk_movie_spm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the DGL graph with movie similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topk_movie_spm.nnz)\n",
    "g = dgl.DGLGraph(topk_movie_spm, readonly=True)\n",
    "g.edata['similarity'] = torch.tensor(topk_movie_spm.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN models\n",
    "\n",
    "We run GNN on the item graph to compute item embeddings. In this tutorial, we use a customized [GraphSage](https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf) model to compute node embeddings. The original GraphSage performs the following computation on every node $v$ in the graph:\n",
    "\n",
    "$$h_{N(v)}^{(l)} \\gets AGGREGATE_k({h_u^{(l-1)}, \\forall u \\in N(v)})$$\n",
    "$$h_v^{(l)} \\gets \\sigma(W^k \\cdot CONCAT(h_v^{(l-1)}, h_{N(v)}^{(l)})),$$\n",
    "\n",
    "where $N(v)$ is the neighborhood of node $v$ and $l$ is the layer Id.\n",
    "\n",
    "The original GraphSage model treats each neighbor equally. However, the SLIM model learns the item similarity based on the user-item iteration. The GNN model should take the similarity into account. Thus, we customize the GraphSage model in the following fashion. Instead of aggregating all neighbors equally, we aggregate neighbors embeddings rescaled by the similarity on the edges. Thus, the aggregation step is defined as follows:\n",
    "\n",
    "$$h_{N(v)}^{(l)} \\gets \\Sigma_{u \\in N(v)}({h_u^{(l-1)} * s_{uv}}),$$\n",
    "\n",
    "where $s_{uv}$ is the similarity score between two vertices $u$ and $v$.\n",
    "\n",
    "The GNN model has multiple layers. In each layer, a vertex accesses its direct neighbors. When we stack $k$ layers in a model, a node $v$ access neighbors within $k$ hops. The output of the GNN model is node embeddings that represent the nodes and all information in the k-hop neighborhood.\n",
    "\n",
    "<img src=\"https://github.com/zheng-da/DGL_devday_tutorial/raw/master/GNN.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "We implement the computation in each layer of the customized GraphSage model in `SAGEConv` and implement the multi-layer model in `GraphSAGEModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sageconv import SAGEConv\n",
    "from dgl.nn.pytorch import conv as dgl_conv\n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 out_dim,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 aggregator_type):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        if n_layers == 1:\n",
    "            self.layers.append(dgl_conv.SAGEConv(in_feats, n_hidden, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=None))\n",
    "        elif n_layers > 1:\n",
    "            # input layer\n",
    "            self.layers.append(dgl_conv.SAGEConv(in_feats, n_hidden, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=activation))\n",
    "            # hidden layer\n",
    "            for i in range(n_layers - 2):\n",
    "                self.layers.append(dgl_conv.SAGEConv(n_hidden, n_hidden, aggregator_type,\n",
    "                                            feat_drop=dropout, activation=activation))\n",
    "            # output layer\n",
    "            self.layers.append(dgl_conv.SAGEConv(n_hidden, out_dim, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=None))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h)\n",
    "            #h = layer(g, h, g.edata['similarity'])\n",
    "            #h = tmp + prev_h\n",
    "            #prev_h = h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Item Embeddings\n",
    "\n",
    "We train the item embeddings with the edges in the item graph as the training signal. This step is very similar to the link prediction task in the [basic applications](https://github.com/zheng-da/DGL_devday_tutorial/blob/master/BasicTasks_pytorch.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the MovieLens dataset has sparse features (both genre and title are stored as multi-hot encoding). The sparse features have many dimensions. To run GNN on the item features, we first create an encoding layer to project the sparse features to a lower dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeLayer(nn.Module):\n",
    "    def __init__(self, in_feats, num_hidden, device):\n",
    "        super(EncodeLayer, self).__init__()\n",
    "        self.proj = nn.Linear(in_feats, int(num_hidden))\n",
    "        #self.emb = nn.Embedding(num_movies, int(num_hidden))\n",
    "        #self.nid = torch.arange(num_movies).to(device)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        #return torch.cat([self.proj(feats), self.emb(self.nid)], 1)\n",
    "        return self.proj(feats)\n",
    "        #return self.emb(self.nid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_embeddings(h, ndata, emb, proj):\n",
    "    '''Combine node-specific trainable embedding ``h`` with categorical inputs\n",
    "    (projected by ``emb``) and numeric inputs (projected by ``proj``).\n",
    "    '''\n",
    "    e = []\n",
    "    for key, value in ndata.items():\n",
    "        if value.dtype == torch.int64:\n",
    "            e.append(emb[key](value))\n",
    "        elif value.dtype == torch.float32:\n",
    "            e.append(proj[key](value))\n",
    "    if len(e) == 0:\n",
    "        return h\n",
    "    else:\n",
    "        return h + torch.stack(e, 0).sum(0)\n",
    "    \n",
    "class EncodeLayer(nn.Module):\n",
    "    def __init__(self, ndata, num_hidden, device):\n",
    "        super(EncodeLayer, self).__init__()\n",
    "        self.proj = nn.ModuleDict()\n",
    "        for key in ndata.keys():\n",
    "            self.proj[key] = nn.Sequential(\n",
    "                                nn.Linear(ndata[key].shape[1], num_hidden),\n",
    "                                nn.LeakyReLU(),\n",
    "                                )\n",
    "    def forward(self, ndata):\n",
    "        return mix_embeddings(0, ndata, None, self.proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FISMrating(nn.Module):\n",
    "    r\"\"\"\n",
    "    PinSAGE + FISM for item-based recommender systems\n",
    "    The formulation of FISM goes as\n",
    "    .. math::\n",
    "       r_{ui} = b_u + b_i + \\left(n_u^+\\right)^{-\\alpha}\n",
    "       \\sum_{j \\in R_u^+} p_j q_i^\\top\n",
    "    In FISM, both :math:`p_j` and :math:`q_i` are trainable parameters.  Here\n",
    "    we replace them as outputs from two PinSAGE models ``P`` and\n",
    "    ``Q``.\n",
    "    \"\"\"\n",
    "    def __init__(self, P, Q, num_users, num_movies, alpha=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.b_u = nn.Parameter(torch.zeros(num_users))\n",
    "        self.b_i = nn.Parameter(torch.zeros(num_movies))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    \n",
    "    def forward(self, I, U, I_neg, I_U, N_U):\n",
    "        '''\n",
    "        I: 1D LongTensor\n",
    "        U: 1D LongTensor\n",
    "        I_neg: 2D LongTensor (batch_size, n_negs)\n",
    "        '''\n",
    "        batch_size = I.shape[0]\n",
    "        device = I.device\n",
    "        I_U = I_U.to(device)\n",
    "        # number of interacted items\n",
    "        N_U = N_U.to(device)\n",
    "        U_idx = torch.arange(U.shape[0], device=device).repeat_interleave(N_U)\n",
    "\n",
    "        q = self.Q(I)\n",
    "        p = self.P(I_U)\n",
    "        p_self = self.P(I)\n",
    "        p_sum = torch.zeros_like(q)\n",
    "        p_sum = p_sum.scatter_add(0, U_idx[:, None].expand_as(p), p)    # batch_size, n_dims\n",
    "        p_ctx = p_sum - p_self\n",
    "        pq = (p_ctx * q).sum(1) / ((N_U.float() - 1).clamp(min=1) ** self.alpha)\n",
    "        r = self.b_u[U] + self.b_i[I] + pq\n",
    "\n",
    "        if I_neg is not None:\n",
    "            n_negs = I_neg.shape[1]\n",
    "            I_neg_flat = I_neg.view(-1)\n",
    "            q_neg = self.Q(I_neg_flat)\n",
    "            q_neg = q_neg.view(batch_size, n_negs, -1)  # batch_size, n_negs, n_dims\n",
    "            pq_neg = (p_ctx.unsqueeze(1) * q_neg).sum(2) / (N_U.float().unsqueeze(1) ** self.alpha)\n",
    "            r_neg = self.b_u[U].unsqueeze(1) + self.b_i[I_neg] + pq_neg\n",
    "            return r, r_neg\n",
    "        else:\n",
    "            return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the FISM model to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0\n",
    "gamma = 0\n",
    "\n",
    "class FISM(nn.Module):\n",
    "    def __init__(self, user_movie_spm, gconv_p, gconv_q, g, num_hidden, device):\n",
    "        super(FISM, self).__init__()\n",
    "        num_users = user_movie_spm.shape[0]\n",
    "        num_movies = user_movie_spm.shape[1]\n",
    "        self.encode_p = EncodeLayer(g.ndata, num_hidden, device)\n",
    "        self.encode_q = EncodeLayer(g.ndata, num_hidden, device)\n",
    "        self.gconv_p = gconv_p\n",
    "        self.gconv_q = gconv_q\n",
    "        P = lambda I: self.gconv_p(g, self.encode_p(g.ndata))[I]\n",
    "        Q = lambda I: self.gconv_q(g, self.encode_q(g.ndata))[I]\n",
    "        self.fism_rating = FISMrating(P, Q, num_users, num_movies, 1)\n",
    "\n",
    "    def est_rating(self, I, U, I_neg, I_U, N_U):\n",
    "        r, r_neg = self.fism_rating(I, U, I_neg, I_U, N_U)\n",
    "        neg_sample_size = int(len(r_neg) / len(r))\n",
    "        return torch.unsqueeze(r, 1), r_neg.reshape((-1, neg_sample_size))\n",
    "\n",
    "    def loss(self, r_ui, neg_r_ui):\n",
    "        diff = 1 - (r_ui - neg_r_ui)\n",
    "        return torch.sum(torch.mul(diff, diff)/2)# \\\n",
    "        #    + beta/2 * torch.sum(torch.mul(P, P) + torch.mul(Q, Q)) \\\n",
    "        #    + gamma/2 * (torch.sum(torch.mul(self.fism_rating.b_u, self.fism_rating.b_u)) \\\n",
    "        #                 + torch.sum(torch.mul(self.fism_rating.b_i, self.fism_rating.b_i)))\n",
    "\n",
    "    def forward(self, I, U, I_neg, I_U, N_U):\n",
    "        r, r_neg = self.fism_rating(I, U, I_neg, I_U, N_U)\n",
    "        neg_sample_size = int(len(r_neg) / len(r))\n",
    "        r_neg = r_neg.reshape((-1, neg_sample_size))\n",
    "        return self.loss(r, r_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeSampler:\n",
    "    def __init__(self, user_movie_spm, batch_size, neg_sample_size):\n",
    "        edge_ids = np.random.permutation(user_movie_spm.nnz)\n",
    "        self.batches = np.split(edge_ids, np.arange(batch_size, len(edge_ids), batch_size))\n",
    "        self.idx = 0\n",
    "        self.users = user_movie_spm.row\n",
    "        self.movies = user_movie_spm.col\n",
    "        self.user_movie_spm = user_movie_spm.tocsr()\n",
    "        self.num_movies = user_movie_spm.shape[1]\n",
    "        self.num_users = user_movie_spm.shape[0]\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.idx == len(batches):\n",
    "            raise StopIteration\n",
    "        batch = self.batches[self.idx]\n",
    "        self.idx += 1\n",
    "        I_neg = np.random.choice(self.num_movies, len(batch) * self.neg_sample_size)\n",
    "        I = self.movies[batch]\n",
    "        U = self.users[batch]\n",
    "        neighbors = self.user_movie_spm[U]\n",
    "        I_neg = I_neg.reshape(-1, self.neg_sample_size)\n",
    "        I = torch.LongTensor(I).to(device)\n",
    "        U = torch.LongTensor(U).to(device)\n",
    "        I_neg = torch.LongTensor(I_neg).to(device)\n",
    "        I_U = torch.LongTensor(neighbors.indices).to(device)\n",
    "        N_U = torch.LongTensor(neighbors.indptr[1:] - neighbors.indptr[:-1]).to(device)\n",
    "        return I, U, I_neg, I_U, N_U\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the performance of the trained item embeddings in the item-based recommendation task. We use the last item that a user purchased to represent the user and compute the similarity between the last item and a list of items (an item the user will purchase and a set of randomly sampled items). We calculate the ranking of the item that will be purchased among the list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecValid(model, user_movie_spm):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        neg_movies_eval = neg_valid[users_valid]\n",
    "        neighbors = user_movie_spm.tocsr()[users_valid]\n",
    "        I_U = torch.LongTensor(neighbors.indices)\n",
    "        N_U = torch.LongTensor(neighbors.indptr[1:] - neighbors.indptr[:-1])\n",
    "        r, neg_r = model.est_rating(torch.LongTensor(movies_valid).to(device),\n",
    "                                    torch.LongTensor(users_valid).to(device),\n",
    "                                    torch.LongTensor(neg_movies_eval).to(device),\n",
    "                                    I_U.to(device),\n",
    "                                    N_U.to(device))\n",
    "        neg_sample_size = int(len(neg_r) / len(r))\n",
    "        neg_r = neg_r.reshape((-1, neg_sample_size))\n",
    "        hits10 = (torch.sum(neg_r >= r, 1) <= 10).cpu().numpy()\n",
    "        return np.mean(hits10)\n",
    "    \n",
    "def RecTest(model, user_movie_spm):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        neg_movies_eval = neg_test[users_test]\n",
    "        neighbors = user_movie_spm.tocsr()[users_test]\n",
    "        I_U = torch.LongTensor(neighbors.indices)\n",
    "        N_U = torch.LongTensor(neighbors.indptr[1:] - neighbors.indptr[:-1])\n",
    "        r, neg_r = model.est_rating(torch.LongTensor(movies_test).to(device),\n",
    "                                    torch.LongTensor(users_test).to(device),\n",
    "                                    torch.LongTensor(neg_movies_eval).to(device),\n",
    "                                    I_U.to(device),\n",
    "                                    N_U.to(device))\n",
    "        neg_sample_size = int(len(neg_r) / len(r))\n",
    "        neg_r = neg_r.reshape((-1, neg_sample_size))\n",
    "        hits10 = (torch.sum(neg_r >= r, 1) <= 10).cpu().numpy()\n",
    "        \n",
    "        f = open(\"test_predict.txt\", \"w\")\n",
    "        for movie, user, score in zip(movies_test, users_test, r):\n",
    "            f.write(str(user) + ', ' + str(int(movie)) + ', ' + str(np.asscalar(score.cpu().numpy())) + ', +1\\n')\n",
    "        for i, user in enumerate(users_test):\n",
    "            for movie, score in zip(neg_movies_eval[i], neg_r[i]):\n",
    "                f.write(str(user) + ', ' + str(int(movie)) + ', ' + str(np.asscalar(score.cpu().numpy())) + ', -1\\n')\n",
    "        f.close()\n",
    "        #for popularity, users in test_deg_dict.items():\n",
    "        #    print(popularity, np.mean(hits10[users]))\n",
    "        return np.mean(hits10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put everything in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "#Model hyperparameters\n",
    "n_hidden = 16\n",
    "n_layers = 0\n",
    "dropout = 0\n",
    "aggregator_type = 'gcn'\n",
    "\n",
    "# create GraphSAGE model\n",
    "gconv_p = GraphSAGEModel(n_hidden,\n",
    "                         n_hidden,\n",
    "                         n_hidden,\n",
    "                         n_layers,\n",
    "                         F.relu,\n",
    "                         dropout,\n",
    "                         aggregator_type)\n",
    "\n",
    "gconv_q = GraphSAGEModel(n_hidden,\n",
    "                         n_hidden,\n",
    "                         n_hidden,\n",
    "                         n_layers,\n",
    "                         F.relu,\n",
    "                         dropout,\n",
    "                         aggregator_type)\n",
    "\n",
    "model = FISM(user_movie_spm, gconv_p, gconv_q, g, n_hidden, device).to(device)\n",
    "g.to(device)\n",
    "features = features.to(device)\n",
    "\n",
    "# Training hyperparameters\n",
    "weight_decay = 1e-3\n",
    "n_epochs = 10\n",
    "lr = 1e-6\n",
    "neg_sample_size = 20\n",
    "\n",
    "# use optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "batch_size = 1024\n",
    "print('#edges:', user_movie_spm.nnz)\n",
    "print('#batch/epoch:', user_movie_spm.nnz/batch_size)\n",
    "\n",
    "# initialize graph\n",
    "dur = []\n",
    "prev_acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for I, U, I_neg, I_U, N_U in EdgeSampler(user_movie_spm, batch_size, neg_sample_size):\n",
    "        loss = model(I, U, I_neg, I_U, N_U)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().item())\n",
    "    \n",
    "    hits10 = RecValid(model, user_movie_spm)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | HITS@10:{:.4f}\".format(epoch, np.mean(losses), np.mean(hits10)))\n",
    "    if prev_acc > hits10:\n",
    "        break\n",
    "    prev_acc = hits10\n",
    "\n",
    "print()\n",
    "# Let's save the trained node embeddings.\n",
    "hits10 = RecTest(model, user_movie_spm)\n",
    "print(\"Test HITS@10:{:.4f}\".format(np.mean(hits10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
