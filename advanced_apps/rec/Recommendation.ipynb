{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setting\n",
    "\n",
    "In this tutorial, we demonstrate how graph neural networks can be used for recommendation. Here we focus on item-based recommendation model. This method in this tutorial recommends items that are similar to the ones purchased by the user. We demonstrate the recommendation model on the MovieLens dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started\n",
    "\n",
    "DGL can be used with different deep learning frameworks. Currently, DGL can be used with Pytorch and MXNet. Here, we show how DGL works with Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we load DGL, we need to set the DGL backend for one of the deep learning frameworks. Because this tutorial develops models in Pytorch, we have to set the DGL backend to Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "\n",
    "# Load Pytorch as backend\n",
    "dgl.load_backend('pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the rest of necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import sparse as spsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the retail rocket dataset\n",
    "\n",
    "First load the session-item set for training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('retail/train_uv.csv', sep='\\t')\n",
    "test_data = pd.read_csv('retail/test_uv.csv', sep='\\t')\n",
    "user_item_spm = spsp.coo_matrix((np.ones(len(train_data)),\n",
    "                                 (np.array(train_data['visitorid']),\n",
    "                                  np.array(train_data['itemid']))))\n",
    "num_items = user_item_spm.shape[1]\n",
    "print(user_item_spm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, we use the previous item used in a session to predict the next item. Here we construct a list of query items (the previous items in a session) and a list of truth item (the item that follows the query item in the session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_edges(data):\n",
    "    data = data.sort_values(by=['visitorid', 'timestamp'])\n",
    "    spm = spsp.coo_matrix((np.ones((len(data))), (data['visitorid'], data['itemid']))).tocsr()\n",
    "    print(spm.nnz)\n",
    "    query = []\n",
    "    truth = []\n",
    "    for i in range(spm.shape[0]):\n",
    "        row = spm[i]\n",
    "        num_items = spm[i].nnz\n",
    "        for t in range(num_items - 1):\n",
    "            query.append(row.indices[t])\n",
    "            truth.append(row.indices[t+1])\n",
    "    query = np.array(query, dtype=np.int64)\n",
    "    truth = np.array(truth, dtype=np.int64)\n",
    "    return query, truth\n",
    "\n",
    "test_query, test_truth = construct_edges(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load item features from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "features = pickle.load(open('retail/retail_item_feats_100.pkl', 'rb'))\n",
    "assert features.shape[0] == num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session-item graph has a strong signal for prediction. Here we use SVD for dimension reduction to generate item features from the session-item graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = spsp.linalg.svds(user_item_spm, k=500)\n",
    "v = vt.transpose() * np.sqrt(s).transpose()\n",
    "features = np.concatenate((features, v), 1)\n",
    "features = torch.tensor(features)\n",
    "in_feats = features.shape[1]\n",
    "print('#feats:', in_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The recommendation model\n",
    "\n",
    "At large, the model first learns item embeddings from the user-item interaction dataset and use the item embeddings to recommend users similar items they have purchased. To learn item embeddings, we first need to construct an item similarity graph and train GNN on the item graph.\n",
    "\n",
    "There are many ways of constructing the item similarity graph. Here we use the [SLIM model](https://dl.acm.org/citation.cfm?id=2118303) to learn item similarity and use the learned result to construct the item graph. The resulting graph will have an edge between two items if they are similar and the edge has a weight that represents the similarity score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the item similarity graph with SLIM\n",
    "SLIM is an item-based recommendation model. When training SLIM on a user-item dataset, it learns an item similarity graph. This similarity graph is the item graph we construct for the GNN model.\n",
    "\n",
    "Please follow the instruction on the [SLIM github repo](https://github.com/KarypisLab/SLIM) to install SLIM.\n",
    "\n",
    "To use SLIM to generate an item similarity graph, there are two hyperparameters we can tune. `l1r` is the co-efficient for the L1 regularization and `l2r` is the co-efficient for the L2 regularization. Increasing `l1r` will generate a sparser similarity graph and increasing `l2r` leads to a denser similarity graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_construct import create_SLIM_graph\n",
    "conv_spm = create_SLIM_graph(user_item_spm, l1r=0.8, l2r=1, test=False)\n",
    "num_items = user_item_spm.shape[1]\n",
    "deg = conv_spm.dot(np.ones((num_items)))\n",
    "print(np.sum(deg == 0))\n",
    "print(conv_spm.sum(0))\n",
    "print(conv_spm.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we construct the item similarity matrix, we load it to the DGL graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_g = dgl.DGLGraph(conv_spm, readonly=True)\n",
    "conv_g.edata['similarity'] = torch.tensor(conv_spm.data, dtype=torch.float32)\n",
    "conv_g.ndata['feats'] = torch.tensor(features, dtype=torch.float32)\n",
    "#g.ndata['id'] = torch.arange(num_items, dtype=torch.int64)\n",
    "print('#nodes:', conv_g.number_of_nodes())\n",
    "print('#edges:', conv_g.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to train the GNN model with some signal. Because our final task is to predict the next item based on the item accessed previously in a session. We construct a loss graph to store the training signal. In this loss graph, two nodes are connected if they are next to each other in a session. Then we train the GNN model on the loss graph in a way similar to the link prediction task in [the previous section](https://github.com/zheng-da/DGL_devday_tutorial/blob/master/BasicTasks_pytorch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query, train_truth = construct_edges(train_data)\n",
    "loss_spm = spsp.coo_matrix((np.ones(len(train_query)), (train_query, train_truth)))\n",
    "print('train graph has #edges:', loss_spm.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to remove the test samples that have appeared in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_spm = loss_spm.tocsr()\n",
    "not_in_train = np.array((loss_spm[test_query, test_truth] == 0).transpose()).squeeze()\n",
    "print('#tests in train:', len(test_query) - np.sum(not_in_train))\n",
    "test_query = test_query[not_in_train]\n",
    "test_truth = test_truth[not_in_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the loss graph to DGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = dgl.DGLGraph(loss_spm, readonly=True)\n",
    "loss_g.edata['similarity'] = torch.tensor(loss_spm.data, dtype=torch.float32)\n",
    "#g.ndata['id'] = torch.arange(num_items, dtype=torch.int64)\n",
    "print('#nodes:', loss_g.number_of_nodes())\n",
    "print('#edges:', loss_g.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN models\n",
    "\n",
    "We run GNN on the item graph to compute item embeddings. In this tutorial, we use a customized [GraphSage](https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf) model to compute node embeddings. The original GraphSage performs the following computation on every node $v$ in the graph:\n",
    "\n",
    "$$h_{N(v)}^{(l)} \\gets AGGREGATE_k({h_u^{(l-1)}, \\forall u \\in N(v)})$$\n",
    "$$h_v^{(l)} \\gets \\sigma(W^k \\cdot CONCAT(h_v^{(l-1)}, h_{N(v)}^{(l)})),$$\n",
    "\n",
    "where $N(v)$ is the neighborhood of node $v$ and $l$ is the layer Id.\n",
    "\n",
    "The original GraphSage model treats each neighbor equally. However, the SLIM model learns the item similarity based on the user-item iteration. The GNN model should take the similarity into account. Thus, we customize the GraphSage model in the following fashion. Instead of aggregating all neighbors equally, we aggregate neighbors embeddings rescaled by the similarity on the edges. Thus, the aggregation step is defined as follows:\n",
    "\n",
    "$$h_{N(v)}^{(l)} \\gets \\Sigma_{u \\in N(v)}({h_u^{(l-1)} * s_{uv}}),$$\n",
    "\n",
    "where $s_{uv}$ is the similarity score between two vertices $u$ and $v$.\n",
    "\n",
    "The GNN model has multiple layers. In each layer, a vertex accesses its direct neighbors. When we stack $k$ layers in a model, a node $v$ access neighbors within $k$ hops. The output of the GNN model is node embeddings that represent the nodes and all information in the k-hop neighborhood.\n",
    "\n",
    "<img src=\"https://github.com/zheng-da/DGL_devday_tutorial/raw/master/GNN.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "We implement the computation in each layer of the customized GraphSage model in `SAGEConv` and implement the multi-layer model in `GraphSAGEModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sageconv import SAGEConv\n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 out_dim,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 aggregator_type):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.proj = nn.Sequential(nn.ReLU(),\n",
    "                                  nn.Linear(out_dim, out_dim),\n",
    "                                  nn.LayerNorm((out_dim,)),\n",
    "                                  )\n",
    "        if n_layers == 1:\n",
    "            self.layers.append(SAGEConv(in_feats, out_dim, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=None))\n",
    "        elif n_layers > 1:\n",
    "            # input layer\n",
    "            self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=activation))\n",
    "            # hidden layer\n",
    "            for i in range(n_layers - 2):\n",
    "                self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type,\n",
    "                                            feat_drop=dropout, activation=activation))\n",
    "            # output layer\n",
    "            self.layers.append(SAGEConv(n_hidden, out_dim, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=None))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h, g.edata['similarity'])\n",
    "        h = self.proj(h)\n",
    "        # normalize embeddings.\n",
    "        #h = F.normalize(h, p=2, dim=1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Item Embeddings\n",
    "\n",
    "We train the item embeddings with the edges in the item graph as the training signal. This step is very similar to the link prediction task in the [basic applications](https://github.com/zheng-da/DGL_devday_tutorial/blob/master/BasicTasks_pytorch.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the MovieLens dataset has sparse features (both genre and title are stored as multi-hot encoding). The sparse features have many dimensions. To run GNN on the item features, we first create an encoding layer to project the sparse features to a lower dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeLayer(nn.Module):\n",
    "    def __init__(self, in_feats, num_hidden):\n",
    "        super(EncodeLayer, self).__init__()\n",
    "        self.proj = nn.Sequential(nn.Linear(in_feats, num_hidden),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(num_hidden, num_hidden),\n",
    "                                  )\n",
    "        #self.emb = nn.Embedding(19174 + 1, num_hidden)\n",
    "        #self.nid = torch.arange(19174).to(device)\n",
    "        \n",
    "    def forward(self, feats):\n",
    "        return self.proj(feats)\n",
    "        #return self.proj(feats) + self.emb(self.nid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to verify if negative edges are true negative edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_spm = loss_spm.tocsr()\n",
    "def verify_neg(neg_g):\n",
    "    false_neg = neg_g.edata['false_neg'].detach().cpu().numpy()\n",
    "    src_nid, dst_nid = neg_g.all_edges(order='eid')\n",
    "    src_nid = neg_g.parent_nid[src_nid].detach().cpu().numpy()\n",
    "    dst_nid = neg_g.parent_nid[dst_nid].detach().cpu().numpy()\n",
    "    true_neg_src = src_nid[false_neg == 0]\n",
    "    true_neg_dst = dst_nid[false_neg == 0]\n",
    "    false_neg_src = src_nid[false_neg == 1]\n",
    "    false_neg_dst = dst_nid[false_neg == 1]\n",
    "    assert np.sum(loss_spm[true_neg_src, true_neg_dst] == 0) == len(true_neg_src)\n",
    "    assert np.sum(loss_spm[false_neg_src, false_neg_dst] != 0) == len(false_neg_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply use node connectivity as the training signal: nodes connected by edges are similar, while nodes not connected by edges are dissimilar.\n",
    "\n",
    "To train such a model, we need to deploy negative sampling to construct negative samples. A positive sample is an edge that exist in the loss graph, while a negative sample is a pair of nodes that don't have an edge between them in the graph. We usually train on each positive sample with multiple negative samples.\n",
    "\n",
    "After having the node embeddings, we compute the similarity scores on positive samples and negative samples. We construct the following ranking loss function on a positive sample and the corresponding negative samples:\n",
    "\n",
    "$$L = (1 - (r_{ij} - \\tilde{r}_{ij}))^2,$$\n",
    "\n",
    "With this loss, training should increase the difference between positive samples and negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCE loss\n",
    "def NCE_loss(pos_score, neg_score, neg_sample_size):\n",
    "    pos_score = F.logsigmoid(pos_score)\n",
    "    neg_score = F.logsigmoid(-neg_score).reshape(-1, neg_sample_size)\n",
    "    return -pos_score - torch.sum(neg_score, dim=1)\n",
    "\n",
    "def rank_loss(pos_score, neg_score, neg_sample_size, mask):\n",
    "    diff = 1 - (pos_score.unsqueeze(1) - neg_score.reshape(-1, neg_sample_size))\n",
    "    mask = mask.reshape(-1, neg_sample_size)\n",
    "    return torch.sum(torch.mul(diff, diff) * mask/2)\n",
    "\n",
    "def rank_loss2(pos_score, neg_score, neg_sample_size, mask):\n",
    "    pos_score = pos_score.unsqueeze(1)\n",
    "    neg_score = neg_score.reshape(-1, neg_sample_size)\n",
    "    mask = mask.reshape(-1, neg_sample_size)\n",
    "    return torch.sum(F.logsigmoid(pos_score - neg_score) * mask) * (-1.0)\n",
    "\n",
    "class GNNRec(nn.Module):\n",
    "    def __init__(self, gconv_model):\n",
    "        super(GNNRec, self).__init__()\n",
    "        self.encode = EncodeLayer(in_feats, n_hidden)\n",
    "        self.gconv_model = gconv_model\n",
    "\n",
    "    def forward(self, conv_g, loss_g, pos_g, neg_g, features, neg_sample_size):\n",
    "        emb = self.encode(features)\n",
    "        emb = self.gconv_model(conv_g, emb)\n",
    "        pos_score = score_func(pos_g, emb)\n",
    "        neg_score = score_func(neg_g, emb)\n",
    "        verify_neg(neg_g)\n",
    "        mask = (1- neg_g.edata['false_neg']).to(emb.device).float()\n",
    "        return torch.mean(rank_loss2(pos_score, neg_score, neg_sample_size, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use dot-product similarity to measure the similarity between two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(g, emb):\n",
    "    src_nid, dst_nid = g.all_edges(order='eid')\n",
    "    # Get the node Ids in the parent graph.\n",
    "    src_nid = g.parent_nid[src_nid]\n",
    "    dst_nid = g.parent_nid[dst_nid]\n",
    "    # Read the node embeddings of the source nodes and destination nodes.\n",
    "    pos_heads = emb[src_nid]\n",
    "    pos_tails = emb[dst_nid]\n",
    "    # cosine similarity\n",
    "    return torch.sum(pos_heads * pos_tails, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the performance of the trained item embeddings in the item-based recommendation task. We use the last item that a user purchased to represent the user and compute the similarity between the last item and all other items and select the most similar items. We calculate the ranking of the item that will be purchased among the list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_score(data):\n",
    "    return np.dot(data, data.transpose())\n",
    "\n",
    "def knnEvaluate(data, query_eval, item_eval, score_fn):\n",
    "    scores = score_fn(data) - np.diag(np.ones(data.shape[0]))\n",
    "    query_scores = scores[query_eval]\n",
    "    truth_scores = np.expand_dims(scores[query_eval,item_eval], 1)\n",
    "    return np.mean(np.sum(query_scores >= truth_scores, 1) < 3)\n",
    "\n",
    "def RecEvaluate(model, g, features, query_eval, item_eval):\n",
    "    gconv_model.eval()\n",
    "    with torch.no_grad():\n",
    "        emb = model.encode(features)\n",
    "        emb = model.gconv_model(g, emb)\n",
    "        return knnEvaluate(emb.cpu().numpy(), query_eval, item_eval, dot_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put everything in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#Model hyperparameters\n",
    "n_hidden = 256\n",
    "n_layers = 2\n",
    "dropout = 0.6\n",
    "aggregator_type = 'sum'\n",
    "\n",
    "# create GraphSAGE model\n",
    "gconv_model = GraphSAGEModel(n_hidden,\n",
    "                             n_hidden,\n",
    "                             n_hidden,\n",
    "                             n_layers,\n",
    "                             F.leaky_relu,\n",
    "                             dropout,\n",
    "                             aggregator_type)\n",
    "    \n",
    "# Model for link prediction\n",
    "model = GNNRec(gconv_model).to(device)\n",
    "conv_g.to(device)\n",
    "loss_g.to(device)\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "features = features.to(device)\n",
    "\n",
    "# Training hyperparameters\n",
    "weight_decay = 1e-3\n",
    "n_epochs = 100\n",
    "lr = 1e-3\n",
    "neg_sample_size = 10\n",
    "\n",
    "# use optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# initialize graph\n",
    "dur = []\n",
    "prev_acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for pos_subg, neg_subg in dgl.contrib.sampling.EdgeSampler(loss_g, batch_size=1024,\n",
    "                                               seed_edges=None,\n",
    "                                               neg_sample_size=neg_sample_size,\n",
    "                                               negative_mode='tail',\n",
    "                                               shuffle=True,\n",
    "                                               return_false_neg=True):\n",
    "        loss = model(conv_g, loss_g, pos_subg, neg_subg, features, neg_sample_size)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().item())\n",
    "    acc = RecEvaluate(model, conv_g, features, test_query, test_truth)\n",
    "    print('Epoch:{}, loss:{:.4f}, HITS@3:{:.4f}'.format(epoch, np.mean(losses), acc))\n",
    "\n",
    "print()\n",
    "# Let's save the trained node embeddings.\n",
    "RecEvaluate(model, conv_g, features, test_query, test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a baseline of an item-based recommendation model. We can consider the sessions that an item has been viewed/purchased as the item feature and recommend the most similar items. Here we use cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "hits_10 = knnEvaluate(user_item_spm.transpose().tocsr(), test_query, test_truth, cosine_similarity)\n",
    "print(hits_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous method, an item has a very high dimension. We can first do dimension reduction with SVD and run KNN on the low-dimension embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_score(data):\n",
    "    return np.dot(data, data.transpose())\n",
    "\n",
    "for d in (1, 10, 20, 40, 80, 160, 320, 640, 1000, 10000):\n",
    "    u, s, vt = spsp.linalg.svds(user_item_spm, k=d)\n",
    "    v = vt.transpose() * np.sqrt(s).transpose()\n",
    "    hits_10 = knnEvaluate(v, test_query, test_truth, dot_score)\n",
    "    print('d={}, hits10={}'.format(d, hits_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_score(data):\n",
    "    return np.dot(data, data.transpose())\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "hits_10 = knnEvaluate(features.cpu().numpy(), test_query, test_truth, dot_score)\n",
    "print(hits_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
