{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems with GNNs\n",
    "\n",
    "The academia and industries have witnessed various attempts and applications of applying GNNs to business applications including recommender systems, fraud detection, etc.\n",
    "\n",
    "In this hands-on tutorial, we will see how GNNs can be used for a recommender system.\n",
    "\n",
    "## Recommender System: Overview\n",
    "\n",
    "Recommender systems are typically used on E-commerce or similar platforms.  It is responsible for predicting the items that are most likely to be interacted by a user, given his/her previous interaction history.\n",
    "\n",
    "Based on whether the interactions have a *rating* that signifies how a user likes an item, we could categorize the interaction data as having either *explicit feedback* if the data has ratings, or *implicit feedback* otherwise.\n",
    "\n",
    "There are a lot of methodologies for recommendation.  Here we will focus on *matrix-factorization-based* methods that expresses users and items as *embeddings* (i.e. vectors of same dimensionality), and the preference of a user to an item as the *dot product* between user and item embeddings.\n",
    "\n",
    "More specifically, for each user we can assign a learnable vector $\\boldsymbol{u}_i$, and for each item we can assign another learnable vector $\\boldsymbol{v}_j$.  Additionally, we also learn a bias for each user $\\beta_i$ and each item $\\gamma_j$, representing the baseline rating of each user and item.  Preference prediction is expressed as $\\hat{r}_{i,j}=\\boldsymbol{u}_i^\\top \\boldsymbol{v}_j + \\beta_i + \\gamma_j$.\n",
    "\n",
    "For explicit feedback datasets, we try to minimize the difference between prediction and ground truth $r_{i,j}$ for all user-item interactions:\n",
    "\n",
    "$$\n",
    "\\min_{\\boldsymbol{u},\\boldsymbol{v}} \\sum_{(i,j)\\in \\mathcal{D}} \\left(\\hat{r}_{i,j} - r_{i,j}\\right)^2\n",
    "$$\n",
    "\n",
    "For implicit feedback datasets, the function to minimize is more complicated, so in this tutorial we will focus on explicit feedback datasets.\n",
    "\n",
    "Other recommender system families include neighborhood-based models, factorization machines, etc.  But we won't go through them here.\n",
    "\n",
    "## What Does a GNN Do in Recommender Systems?\n",
    "\n",
    "GNNs most commonly appear as a another method of computing the user and item embeddings: instead of directly assigning a learnable vector as user and item embedding, we compute the embeddings with a GNN.  The graph for the GNN would be the interaction data itself, with users and items as two types of nodes and the interactions as edges connecting the nodes.  \n",
    "\n",
    "Comparing against other approaches, the biggest advantage of GNNs in recommender systems is that it can potentially combine the interactions data with other kind of relational data.  If we have additional relational data such as social networks or knowledge graphs, we can combine those data with the interaction data to form a bigger graph, and still run the same GNN as a recommender system.  Other advantages include ability of introducing the information of neighbors to embeddings, and the ability to combine both user/item features and the neighborhood structure of users/items, etc.\n",
    "\n",
    "In our hands-on, we will use the MovieLens-100K dataset.\n",
    "\n",
    "Note that to simplify stuff in our tutorial,\n",
    "\n",
    "* We ignore the user and item features.\n",
    "* We would not be considering new users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('ua.base', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "test_data = pd.read_csv('ua.test', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Remove the entries with users and items not appearing in the training dataset\n",
    "test_data = test_data[test_data['user_id'].isin(train_data['user_id']) &\n",
    "                      test_data['item_id'].isin(train_data['item_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterogeneous Graphs in DGL\n",
    "\n",
    "If we treat our interaction data as a graph, we will have two types of nodes: users and items.  We call a graph that has multiple node types and edge types a *heterogeneous* graph.\n",
    "\n",
    "With MovieLens-100K loaded, we will see how to build a heterogeneous graph from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "# Relabel the user IDs and item IDs to integers\n",
    "train_data = train_data.astype({'user_id': 'category', 'item_id': 'category'})\n",
    "test_data = test_data.astype({'user_id': 'category', 'item_id': 'category'})\n",
    "# We need to keep the relabeling between training and test data consistent\n",
    "test_data['user_id'].cat.set_categories(train_data['user_id'].cat.categories, inplace=True)\n",
    "test_data['item_id'].cat.set_categories(train_data['item_id'].cat.categories, inplace=True)\n",
    "\n",
    "train_user_ids = torch.LongTensor(train_data['user_id'].cat.codes.values)\n",
    "train_item_ids = torch.LongTensor(train_data['item_id'].cat.codes.values)\n",
    "train_ratings = torch.LongTensor(train_data['rating'].values)\n",
    "test_user_ids = torch.LongTensor(test_data['user_id'].cat.codes.values)\n",
    "test_item_ids = torch.LongTensor(test_data['item_id'].cat.codes.values)\n",
    "test_ratings = torch.LongTensor(test_data['rating'].values)\n",
    "\n",
    "# Build graph\n",
    "graph = dgl.heterograph({\n",
    "    # Heterogeneous graphs are organized as a dictionary of edges connecting two types of nodes.\n",
    "    # We specify the edges of a type simply with a pair of user ID array and item ID array.\n",
    "    ('user', 'watched', 'item'): (train_user_ids, train_item_ids),\n",
    "    # Since DGL graphs are directional, we need an inverse relation from items to users as well.\n",
    "    ('item', 'watched-by', 'user'): (train_item_ids, train_user_ids)\n",
    "})\n",
    "\n",
    "# Assign ratings\n",
    "graph.edges['watched'].data['rating'] = torch.LongTensor(train_ratings)\n",
    "graph.edges['watched-by'].data['rating'] = torch.LongTensor(train_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model on Heterogeneous Graphs\n",
    "\n",
    "### Define Dataset to Sample Minibatches from\n",
    "\n",
    "The first thing we need to do for GNN training is to define how a minibatch of examples look like.  For rating prediction tasks, a minibatch consists of pairs of users and items.  So we create a torch `Dataset` object that contains all training pairs of users and items as well as their ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_user_ids, train_item_ids, train_ratings)\n",
    "test_dataset = TensorDataset(test_user_ids, test_item_ids, test_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Minibatch & Neighbor Sampler\n",
    "\n",
    "For an interaction we wish to compute the representation of its user and its item with a multi-layer GNN.  Therefore, as in the previous tutorial, we need to define a minibatch sampler that gets us the computation dependency of the user and item nodes for the multi-layer GNN.  At the same time, we also want to keep track of the training interactions themselves, i.e. which user is interacting which item.\n",
    "\n",
    "In DGL, rating prediction could be achieved with the following steps:\n",
    "\n",
    "1. Create a *pair graph* that consists of all the users and items in the dataset, but only with the interactions in the training minibatch.\n",
    "2. *Compact* the graph to remove all unnecessary nodes, keeping only the nodes with some edges going in or out.\n",
    "3. Construct blocks bottom-up for computing the multi-layer output of the nodes, as in the previous tutorial.\n",
    "4. Propagate messages top-down to obtain the output from the GNN.\n",
    "5. Copy the output to the pair graph and compute the preference with `apply_edges()` method.\n",
    "\n",
    "The following cell has the code of completing step 1 to step 3, which constitutes the steps of obtaining computation dependency for the interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchSampler(object):\n",
    "    def __init__(self, graph, num_layers):\n",
    "        self.graph = graph\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def sample(self, batch):\n",
    "        # Convert the list of user-item-rating triplets into a triplet of users, items, and ratings\n",
    "        users, items, ratings = zip(*batch)\n",
    "        users = torch.stack(users)\n",
    "        items = torch.stack(items)\n",
    "        ratings = torch.stack(ratings)\n",
    "        \n",
    "        # Create a pair graph (Step 1)\n",
    "        pair_graph = dgl.heterograph(\n",
    "            {('user', 'watched', 'item'): (users, items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        \n",
    "        # Compact the graph (Step 2)\n",
    "        pair_graph = dgl.compact_graphs(pair_graph)\n",
    "        # Assign ratings to the graph\n",
    "        pair_graph.edata['rating'] = ratings\n",
    "        \n",
    "        # Construct blocks (Step 3)\n",
    "        seeds = {'user': pair_graph.nodes['user'].data[dgl.NID],\n",
    "                 'item': pair_graph.nodes['item'].data[dgl.NID]}\n",
    "        blocks = self.construct_blocks(seeds, (users, items))\n",
    "            \n",
    "        return pair_graph, blocks\n",
    "        \n",
    "    def construct_blocks(self, seeds, user_item_pairs_to_remove):\n",
    "        blocks = []\n",
    "        users, items = user_item_pairs_to_remove\n",
    "        for i in range(self.num_layers):\n",
    "            # We take all neighbors to form the sampled graph for computing the node representations on the\n",
    "            # current layer.\n",
    "            sampled_graph = dgl.in_subgraph(self.graph, seeds)\n",
    "            # Find the sampled edge IDs for both directions\n",
    "            sampled_eids = sampled_graph.edges['watched'].data[dgl.EID]\n",
    "            sampled_eids_rev = sampled_graph.edges['watched-by'].data[dgl.EID]\n",
    "            \n",
    "            # A subtlety of rating prediction and link prediction is that, when we train on the pair of user A\n",
    "            # and item 1, we don't want to actually tell the GNN that \"user A has a connection to item 1\".  So\n",
    "            # we should remove all edges connecting the training pairs from the sampled graph.\n",
    "            _, _, edges_to_remove = sampled_graph.edge_ids(users, items, etype='watched', return_uv=True)\n",
    "            _, _, edges_to_remove_rev = sampled_graph.edge_ids(items, users, etype='watched-by', return_uv=True)\n",
    "            sampled_with_edges_removed = dgl.remove_edges(\n",
    "                sampled_graph, {'watched': edges_to_remove, 'watched-by': edges_to_remove_rev})\n",
    "            sampled_eids = sampled_eids[sampled_with_edges_removed.edges['watched'].data[dgl.EID]]\n",
    "            sampled_eids_rev = sampled_eids_rev[sampled_with_edges_removed.edges['watched-by'].data[dgl.EID]]\n",
    "            \n",
    "            # Create a block from the sampled graph.\n",
    "            block = dgl.to_block(sampled_with_edges_removed, seeds)\n",
    "            blocks.insert(0, block)\n",
    "            seeds = {'user': block.srcnodes['user'].data[dgl.NID],\n",
    "                     'item': block.srcnodes['item'].data[dgl.NID]}\n",
    "            block.edges['watched'].data['rating'] = \\\n",
    "                self.graph.edges['watched'].data['rating'][sampled_eids]\n",
    "            block.edges['watched-by'].data['rating'] = \\\n",
    "                self.graph.edges['watched-by'].data['rating'][sampled_eids_rev]\n",
    "            \n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "\n",
    "We choose a simplified version of Graph Convolutional Matrix Completion (GCMC) as the model.  Each node sends a message to its neighbors by computing a rating-specific projection of the node's representation.  Then each node gathers the messages and takes an average, projecting it afterwards.\n",
    "\n",
    "More specifically, given a user node $i$ with its input representations $u_i^{l-1}$ on layer $l$, we\n",
    "\n",
    "1. Find all neighbors, i.e. interacted items, of $i$.\n",
    "2. For each item $j$, check the rating $r_{ij}$ between user $i$ and item $j$.  The message sent from item $j$ to user $i$ would be a rating-specific linear projection $m_{j\\to i}^l \\gets W_{r_{ij}}^l v_j^{l-1}$.  $W_{r_{ij}}^l$ is a learnable matrix.\n",
    "3. The user $i$ aggregates all incoming messages by averaging and updates itself: $u_i^l \\gets \\mathrm{ReLU}(W^l[\\mathrm{Average}(m_{j\\to i}^l); u_i^{l-1}])$.  $W^l$ is again a learnable matrix.\n",
    "\n",
    "We can similarly compute $v_j$, the representation of an item node $j$.\n",
    "\n",
    "For an implementation faithful to the paper, please see our model examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "class GCMCLayer(nn.Module):\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Weights for user nodes\n",
    "        self.W_r = nn.Parameter(torch.randn(num_ratings + 1, hidden_dims, hidden_dims))\n",
    "        self.W = nn.Linear(hidden_dims * 2, hidden_dims)\n",
    "        \n",
    "        # Weights for item nodes\n",
    "        self.V_r = nn.Parameter(torch.randn(num_ratings + 1, hidden_dims, hidden_dims))\n",
    "        self.V = nn.Linear(hidden_dims * 2, hidden_dims)\n",
    "        \n",
    "    def compute_message(self, W, edges):\n",
    "        W_r = W[edges.data['rating']]\n",
    "        h = edges.src['h']\n",
    "        m = (W_r @ h.unsqueeze(-1)).squeeze(2)\n",
    "        return m\n",
    "        \n",
    "    def forward(self, block, input_user_features, input_item_features):\n",
    "        with block.local_scope():\n",
    "            block.srcnodes['user'].data['h'] = input_user_features\n",
    "            block.srcnodes['item'].data['h'] = input_item_features\n",
    "            \n",
    "            block.dstnodes['user'].data['h'] = input_user_features[:block.number_of_dst_nodes('user')]\n",
    "            block.dstnodes['item'].data['h'] = input_item_features[:block.number_of_dst_nodes('item')]\n",
    "            \n",
    "            # Compute messages\n",
    "            block.apply_edges(\n",
    "                lambda edges: {'m': self.compute_message(self.W_r, edges)},\n",
    "                etype='watched')\n",
    "            block.apply_edges(\n",
    "                lambda edges: {'m': self.compute_message(self.V_r, edges)},\n",
    "                etype='watched-by')\n",
    "            \n",
    "            # Aggregate messages\n",
    "            block.update_all(fn.copy_e('m', 'm'), fn.mean('m', 'h_neigh'), etype='watched')\n",
    "            block.update_all(fn.copy_e('m', 'm'), fn.mean('m', 'h_neigh'), etype='watched-by')\n",
    "            \n",
    "            # Updates the representations of output users and items\n",
    "            block.dstnodes['user'].data['h'] = F.relu(\n",
    "                self.W(torch.cat([block.dstnodes['user'].data['h'], block.dstnodes['user'].data['h_neigh']], 1)))\n",
    "            block.dstnodes['item'].data['h'] = F.relu(\n",
    "                self.W(torch.cat([block.dstnodes['item'].data['h'], block.dstnodes['item'].data['h_neigh']], 1)))\n",
    "            \n",
    "            return block.dstnodes['user'].data['h'], block.dstnodes['item'].data['h']\n",
    "        \n",
    "class GCMCRating(nn.Module):\n",
    "    def __init__(self, num_users, num_items, hidden_dims, num_ratings, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, hidden_dims)\n",
    "        self.item_embeddings = nn.Embedding(num_items, hidden_dims)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            GCMCLayer(hidden_dims, num_ratings) for _ in range(num_layers)])\n",
    "        \n",
    "        self.W = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.V = nn.Linear(hidden_dims, hidden_dims)\n",
    "        \n",
    "    def forward(self, blocks):\n",
    "        # Propagate messages top-down (Step 4)\n",
    "        # We start with a learnable embedding for each user and item.  Then we compute the GNN\n",
    "        # outputs with those learnable embeddings as inputs.\n",
    "        user_embeddings = self.user_embeddings(blocks[0].srcnodes['user'].data[dgl.NID])\n",
    "        item_embeddings = self.item_embeddings(blocks[0].srcnodes['item'].data[dgl.NID])\n",
    "        for block, layer in zip(blocks, self.layers):\n",
    "            user_embeddings, item_embeddings = layer(block, user_embeddings, item_embeddings)\n",
    "        \n",
    "        # Compute predicted preference (Step 5)\n",
    "        user_embeddings = self.W(user_embeddings)\n",
    "        item_embeddings = self.V(item_embeddings)\n",
    "        \n",
    "        return user_embeddings, item_embeddings\n",
    "        \n",
    "    def compute_score(self, pair_graph, user_embeddings, item_embeddings):\n",
    "        with pair_graph.local_scope():\n",
    "            pair_graph.nodes['user'].data['h'] = user_embeddings\n",
    "            pair_graph.nodes['item'].data['h'] = item_embeddings\n",
    "            pair_graph.apply_edges(fn.u_dot_v('h', 'h', 'r'))\n",
    "            \n",
    "            return pair_graph.edata['r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluation Metric\n",
    "\n",
    "In this tutorial we use root of mean squared error (RMSE) as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, label):\n",
    "    return ((pred - label) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "Note: in this tutorial we are directly validating on the test set for simplicity.  In practice we should split out some data points in the training set to form a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:20<00:00,  8.70it/s, loss=1.3460]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.68it/s]\n",
      "  1%|          | 1/182 [00:00<00:20,  8.69it/s, loss=1.7618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3404474258422852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:20<00:00,  8.68it/s, loss=1.1464]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.11it/s]\n",
      "  1%|          | 1/182 [00:00<00:21,  8.25it/s, loss=1.1970]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1713429689407349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:21<00:00,  8.61it/s, loss=1.0676]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.45it/s]\n",
      "  1%|          | 1/182 [00:00<00:21,  8.43it/s, loss=1.1370]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1040641069412231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:21<00:00,  8.66it/s, loss=0.9172]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.41it/s]\n",
      "  1%|          | 1/182 [00:00<00:21,  8.34it/s, loss=1.0179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0660336017608643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:20<00:00,  8.68it/s, loss=0.7375]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.67it/s]\n",
      "  1%|          | 1/182 [00:00<00:21,  8.34it/s, loss=0.9540]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0414881706237793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:20<00:00,  8.71it/s, loss=0.4587]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.41it/s]\n",
      "  1%|          | 1/182 [00:00<00:22,  8.05it/s, loss=0.9233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0260186195373535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:20<00:00,  8.70it/s, loss=0.7890]\n",
      "100%|██████████| 19/19 [00:00<00:00, 19.86it/s]\n",
      "  1%|          | 1/182 [00:00<00:22,  8.05it/s, loss=0.9748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.014702558517456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:21<00:00,  8.50it/s, loss=1.0889]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.54it/s]\n",
      "  1%|          | 1/182 [00:00<00:23,  7.82it/s, loss=0.8516]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0056449174880981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 130/182 [00:15<00:06,  8.54it/s, loss=1.0727]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dbda425c8ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpair_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0muser_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fe5e5d89ff78>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     24\u001b[0m         seeds = {'user': pair_graph.nodes['user'].data[dgl.NID],\n\u001b[1;32m     25\u001b[0m                  'item': pair_graph.nodes['item'].data[dgl.NID]}\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpair_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fe5e5d89ff78>\u001b[0m in \u001b[0;36mconstruct_blocks\u001b[0;34m(self, seeds, user_item_pairs_to_remove)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# we should remove all edges connecting the training pairs from the sampled graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_to_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'watched'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_to_remove_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'watched-by'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             sampled_with_edges_removed = dgl.remove_edges(\n\u001b[1;32m     47\u001b[0m                 sampled_graph, {'watched': edges_to_remove, 'watched-by': edges_to_remove_rev})\n",
      "\u001b[0;32m~/Git/dgl/python/dgl/heterograph.py\u001b[0m in \u001b[0;36medge_ids\u001b[0;34m(self, u, v, force_multi, return_uv, etype)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_multi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             dgl_warning(\"force_multi will be deprecated, \" \\\n",
      "\u001b[0;32m~/Git/dgl/python/dgl/heterograph_index.py\u001b[0m in \u001b[0;36medge_ids\u001b[0;34m(self, etype, u, v)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mu_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodgltensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mv_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodgltensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0medge_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CAPI_DGLHeteroEdgeIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/dgl/python/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# In this tutorial we consider 1-layer GNNs.\n",
    "NUM_LAYERS = 1\n",
    "BATCH_SIZE = 500\n",
    "NUM_EPOCHS = 50\n",
    "HIDDEN_DIMS = 8\n",
    "\n",
    "sampler = MinibatchSampler(graph, NUM_LAYERS)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=False)\n",
    "\n",
    "model = GCMCRating(graph.number_of_nodes('user'), graph.number_of_nodes('item'), HIDDEN_DIMS, 5, NUM_LAYERS)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for _ in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(train_dataloader) as t:\n",
    "        for pair_graph, blocks in t:\n",
    "            user_emb, item_emb = model(blocks)\n",
    "            prediction = model.compute_score(pair_graph, user_emb, item_emb)\n",
    "            loss = ((prediction - pair_graph.edata['rating']) ** 2).mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            t.set_postfix({'loss': '%.4f' % loss.item()}, refresh=False)\n",
    "    model.eval()\n",
    "    with tqdm.tqdm(test_dataloader) as t:\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            ratings = []\n",
    "            for pair_graph, blocks in t:\n",
    "                user_emb, item_emb = model(blocks)\n",
    "                prediction = model.compute_score(pair_graph, user_emb, item_emb)\n",
    "                predictions.append(prediction)\n",
    "                ratings.append(pair_graph.edata['rating'])\n",
    "\n",
    "            predictions = torch.cat(predictions, 0)\n",
    "            ratings = torch.cat(ratings, 0)\n",
    "    print('RMSE:', rmse(predictions, ratings).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Defining Minibatch Sampler for Implicit Feedback\n",
    "\n",
    "For implicit feedback datasets, instead of predicting the rating between a user and an item, we often need to predict whether a user would interact the item.  Since there is no rating for us to compute the loss, we instead rely on negative sampling for training.\n",
    "\n",
    "An example of training with negative sampling goes as follows.  For each user-item pair $(i,j)$ that appeared as an interaction (called *positive* example), we corrupt the item with a randomly-sampled item $j'$ (called *negative* example).  The model is then responsible for distinguishing whether the user-item pair is positive or negative.  The loss function for training implicit feedback can typically be any binary classification loss, for instance, a hinge loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{(i,j)\\in D, j'} \\max(\\hat{r}_{i,j'} - \\hat{r}_{i,j} + 1, 0)\n",
    "$$\n",
    "\n",
    "In graph learning we usually refer to this problem as *link prediction*, i.e. predicting whether an edge exists between two nodes.  In DGL it could be achieved with the following steps (the difference from rating prediction highlighted in bold):\n",
    "\n",
    "1. **Create two *pair graphs* that consists of all the users and items in the dataset, but only with the interactions in the training minibatch of positive examples and negative examples respectively.**\n",
    "2. *Compact* **both graphs** to remove all unnecessary nodes, keeping only the nodes with some edges going in or out.\n",
    "3. Construct blocks bottom-up for computing the multi-layer output of the nodes, as in the previous tutorial.\n",
    "4. Propagate messages top-down to obtain the output from the GNN.\n",
    "5. Copy the output to **both pair graphs** and compute the preference with `apply_edges()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictionMinibatchSampler(MinibatchSampler):\n",
    "    def __init__(self, graph, num_layers):\n",
    "        self.graph = graph\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def sample(self, batch):\n",
    "        # Convert the list of user-item-rating triplets into a pairs of users and items\n",
    "        users, items, _ = zip(*batch)\n",
    "        users = torch.stack(users)\n",
    "        items = torch.stack(items)\n",
    "        # Get corrupted items for negative examples\n",
    "        neg_items = torch.randint(0, self.graph.number_of_nodes('item'), (len(users),))\n",
    "        \n",
    "        # Create a pair graph for positive examples and negative examples (Step 1)\n",
    "        pos_pair_graph = dgl.heterograph(\n",
    "            {('user', 'watched', 'item'): (users, items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        neg_pair_graph = dgl.heterograph(\n",
    "            {('user', 'watched', 'item'): (users, neg_items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        \n",
    "        # Compact the graph (Step 2)\n",
    "        pos_pair_graph, neg_pair_graph = dgl.compact_graphs([pos_pair_graph, neg_pair_graph])\n",
    "        \n",
    "        # Construct blocks (Step 3)\n",
    "        # Note that pos_pair_graph and neg_pair_graph have the same set of users and items, so we only need\n",
    "        # to check one of them to get the seed nodes.\n",
    "        seeds = {'user': pos_pair_graph.nodes['user'].data[dgl.NID],\n",
    "                 'item': pos_pair_graph.nodes['item'].data[dgl.NID]}\n",
    "        # Note that here we would also remove edges connecting between users and both the corresponding positive\n",
    "        # and negative items appearing in the minibatch.\n",
    "        blocks = self.construct_blocks(seeds, (torch.cat([users, users]), torch.cat([items, neg_items])))\n",
    "            \n",
    "        return pair_graph, blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With minibatch sampler defined for link prediction, we only need to rewrite the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
